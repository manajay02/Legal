# ============================================
# Legal Argument Critic API - Configuration
# ============================================

# ============================================
# 1. INFERENCE BACKEND (Choose ONE)
# ============================================

# Backend options: "openrouter", "gemini", or "ollama"
INFERENCE_BACKEND=openrouter

# ============================================
# 2. OPENROUTER (Recommended - Free)
# ============================================
# Get API key: https://openrouter.ai/
# Free models: deepseek/deepseek-chat (no rate limits)

OPENROUTER_API_KEY=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
OPENROUTER_MODEL=deepseek/deepseek-chat
OPENROUTER_TEMPERATURE=0.7
OPENROUTER_MAX_TOKENS=2048

# ============================================
# 3. GOOGLE GEMINI (Alternative)
# ============================================
# Get API key: https://aistudio.google.com/
# Free tier: 15 RPM limit

GOOGLE_API_KEY=your_google_api_key_here
GEMINI_MODEL_NAME=gemini-1.5-flash
GEMINI_TEMPERATURE=0.7
GEMINI_MAX_TOKENS=2048

# ============================================
# 4. OLLAMA (Local Fine-Tuned Model)
# ============================================
# Requires: NVIDIA GPU with 8GB+ VRAM
# Setup: python scripts/merge_and_convert_ollama.py

OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=legal-critic
OLLAMA_MODELS=D:\LegalScoreModel\.ollama\models

# ============================================
# HOW TO SWITCH BACKENDS
# ============================================

# For OpenRouter (Free, Recommended):
#   INFERENCE_BACKEND=openrouter
#   Set OPENROUTER_API_KEY

# For Gemini:
#   INFERENCE_BACKEND=gemini
#   Set GOOGLE_API_KEY

# For Local Fine-Tuned Model:
#   INFERENCE_BACKEND=ollama
#   Run: python scripts/merge_and_convert_ollama.py
#   Start Ollama: ollama serve
